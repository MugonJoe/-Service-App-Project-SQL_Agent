{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain langgraph langchain-openai langchain-community langsmith python-dotenv"
      ],
      "metadata": {
        "id": "rnyxHLwgyzgz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# My SQL Agent Project\n",
        "# - Chinook SQLite DB\n",
        "# - LangChain + LangGraph\n",
        "# =========================================================\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import uuid\n",
        "import requests\n",
        "\n",
        "# (선택) .env 사용\n",
        "try:\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv()\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"Key\"\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "MODEL_NAME = \"gpt-4o\"\n",
        "# MODEL_NAME = \"mistral-large-latest\"\n",
        "print(\"Using model:\", MODEL_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ib5Eb18Gyzm6",
        "outputId": "50c6e12f-36c7-4540-f88d-c2760d500326"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using model: gpt-4o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 1) SQLite DB (Chinook) 다운로드 & 로드\n",
        "# =========================================================\n",
        "db_path = Path(\"Chinook.db\")\n",
        "\n",
        "if not db_path.exists():\n",
        "    url = \"https://storage.googleapis.com/benchmarks-artifacts/chinook/Chinook.db\"\n",
        "    r = requests.get(url)\n",
        "    if r.status_code == 200:\n",
        "        with open(db_path, \"wb\") as f:\n",
        "            f.write(r.content)\n",
        "        print(\"Chinook.db downloaded.\")\n",
        "    else:\n",
        "        raise RuntimeError(f\"Failed to download Chinook.db: {r.status_code}\")\n",
        "else:\n",
        "    print(\"Chinook.db already exists.\")\n",
        "\n",
        "from langchain_community.utilities import SQLDatabase\n",
        "\n",
        "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
        "print(\"DB dialect:\", db.dialect)\n",
        "print(\"Tables:\", db.get_usable_table_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nvTLM-k1JJf",
        "outputId": "2b82d537-11ac-483d-9096-7492f135f5f3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chinook.db already exists.\n",
            "DB dialect: sqlite\n",
            "Tables: ['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 2) ToolNode + Fallback 유틸\n",
        "# =========================================================\n",
        "from typing import Any, Annotated, Literal\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langchain_core.messages import ToolMessage, AIMessage, HumanMessage, AnyMessage\n",
        "from langchain_core.runnables import RunnableLambda, RunnableWithFallbacks\n",
        "\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "def handle_tool_error(state) -> dict:\n",
        "    #Tool 실행 중 에러 발생 시, LLM에게 에러 내용 그대로 전달\n",
        "    error = state.get(\"error\")\n",
        "    tool_calls = state[\"messages\"][-1].tool_calls\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            ToolMessage(\n",
        "                content=f\"Here is the error: {repr(error)}\\n\\nPlease fix your mistakes.\",\n",
        "                tool_call_id=tc[\"id\"],\n",
        "            )\n",
        "            for tc in tool_calls\n",
        "        ]\n",
        "    }\n",
        "\n",
        "def create_tool_node_with_fallback(tools: list) -> RunnableWithFallbacks[Any, dict]:\n",
        "    #ToolNode + 예외 처리 fallback 래핑\n",
        "    return ToolNode(tools).with_fallbacks(\n",
        "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "AxJlvu4t1We3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 3) SQL Toolkit & Custom Tool 정의\n",
        "# =========================================================\n",
        "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
        "\n",
        "toolkit = SQLDatabaseToolkit(db=db, llm=ChatOpenAI(model=MODEL_NAME))\n",
        "tools = toolkit.get_tools()\n",
        "\n",
        "list_tables_tool = next(t for t in tools if t.name == \"sql_db_list_tables\")\n",
        "get_schema_tool = next(t for t in tools if t.name == \"sql_db_schema\")\n",
        "\n",
        "print(\"list_tables_tool / get_schema_tool ready.\")\n",
        "\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def db_query_tool(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Chinook SQLite DB에 대해 SELECT 쿼리를 실행하고 결과를 문자열로 반환, 실패 시 간단한 에러 메시지 반환\n",
        "    \"\"\"\n",
        "    result = db.run_no_throw(query)\n",
        "    if not result:\n",
        "        return \"Error: Query failed. Please rewrite your query and try again.\"\n",
        "    return result\n",
        "\n",
        "print(\"db_query_tool ready.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2M9z_MV4QkU",
        "outputId": "bccfc94b-cdc9-4672-ee36-d5efde2b11b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "list_tables_tool / get_schema_tool ready.\n",
            "db_query_tool ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 4) SQL Query Checker (LLM)\n",
        "# =========================================================\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "query_check_system = \"\"\"\n",
        "You are a SQL expert with a strong attention to detail.\n",
        "You are helping in a personal project that builds a SQL agent\n",
        "over the Chinook SQLite database.\n",
        "\n",
        "Double check the SQLite query for common mistakes, including:\n",
        "- Using NOT IN with NULL values\n",
        "- Using UNION when UNION ALL should have been used\n",
        "- Using BETWEEN for exclusive ranges\n",
        "- Data type mismatch in predicates\n",
        "- Properly quoting identifiers\n",
        "- Using the correct number of arguments for functions\n",
        "- Casting to the correct data type\n",
        "- Using the proper columns for joins\n",
        "\n",
        "If there are any of the above mistakes, rewrite the query.\n",
        "If there are no mistakes, just reproduce the original query.\n",
        "\n",
        "You will call the appropriate tool to execute the query after running this check.\n",
        "\"\"\"\n",
        "\n",
        "query_check_prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", query_check_system), (\"placeholder\", \"{messages}\")]\n",
        ")\n",
        "\n",
        "# 여기서는 db_query_tool \"만\" tool로 바인딩 (정상)\n",
        "query_check_llm = ChatOpenAI(\n",
        "    model=MODEL_NAME,\n",
        "    temperature=0,\n",
        ").bind_tools([db_query_tool], tool_choice=\"db_query_tool\")\n",
        "\n",
        "# prompt | llm 체인\n",
        "query_check = query_check_prompt | query_check_llm\n",
        "\n",
        "print(\"query_check chain ready.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_nAgr0J4RgV",
        "outputId": "eb1bf4a8-dc83-4eb8-b9bf-8f5b6f91f0f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query_check chain ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 5) 에이전트 State & 그래프 초기화\n",
        "# =========================================================\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], add_messages]\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# (1) 테이블 목록 가져오기\n",
        "# ---------------------------------------------------------\n",
        "def first_tool_call(state: AgentState) -> dict[str, list[AIMessage]]:\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            AIMessage(\n",
        "                content=\"\",\n",
        "                tool_calls=[\n",
        "                    {\n",
        "                        \"name\": \"sql_db_list_tables\",\n",
        "                        \"args\": {},\n",
        "                        \"id\": \"initial_tool_call\",\n",
        "                    }\n",
        "                ],\n",
        "            )\n",
        "        ]\n",
        "    }\n",
        "\n",
        "workflow.add_node(\"first_tool_call\", first_tool_call)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# (2) list_tables_tool / get_schema_tool / schema LLM\n",
        "# ---------------------------------------------------------\n",
        "workflow.add_node(\n",
        "    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n",
        ")\n",
        "\n",
        "from langchain_openai import ChatOpenAI as OpenAIChat\n",
        "\n",
        "schema_llm = OpenAIChat(\n",
        "    model=MODEL_NAME, temperature=0\n",
        ").bind_tools([get_schema_tool])\n",
        "\n",
        "def model_get_schema(state: AgentState) -> dict[str, list[AIMessage]]:\n",
        "    return {\"messages\": [schema_llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "workflow.add_node(\"model_get_schema\", model_get_schema)\n",
        "workflow.add_node(\n",
        "    \"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool])\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nNePDZ34T43",
        "outputId": "757a13f1-601b-482c-b024-48485a2cac8f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7cd44d9f5c40>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 6) 쿼리 생성/해석 LLM\n",
        "# =========================================================\n",
        "QUERY_GEN_INSTRUCTION = \"\"\"\n",
        "You are a SQL expert with a strong attention to detail.\n",
        "\n",
        "You are helping with a personal project: a SQL agent over the Chinook\n",
        "SQLite database (a digital media store).\n",
        "\n",
        "You can:\n",
        "- Define SQL queries,\n",
        "- Analyze query results,\n",
        "- Interpret the results and answer the user's question.\n",
        "\n",
        "Read the messages below and identify:\n",
        "- User question\n",
        "- Table schemas (DDL)\n",
        "- Query statements and query results (or errors), if any.\n",
        "\n",
        "Rules:\n",
        "\n",
        "1. If there is no query result yet that can answer the question,\n",
        "   create a syntactically correct SQLite query to answer the user question.\n",
        "   DO NOT run any DML statements (INSERT, UPDATE, DELETE, DROP, etc.).\n",
        "\n",
        "2. If you create a query, respond ONLY with the query statement.\n",
        "   Example: \"SELECT * FROM Artist LIMIT 5;\"\n",
        "\n",
        "3. If a query was already executed but produced an error,\n",
        "   respond with the same error message you found.\n",
        "   Example: \"Error: Artist table doesn't exist\"\n",
        "\n",
        "4. If a query was already executed successfully,\n",
        "   interpret the result and answer the question with this pattern:\n",
        "   Answer: <<question answer>>\n",
        "\"\"\"\n",
        "\n",
        "query_gen_prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", QUERY_GEN_INSTRUCTION), (\"placeholder\", \"{messages}\")]\n",
        ")\n",
        "\n",
        "query_gen_llm = OpenAIChat(\n",
        "    model=MODEL_NAME,\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "def query_gen_node(state: AgentState):\n",
        "    \"\"\"\n",
        "    - 쿼리가 필요하면: SQL 문자열만 생성\n",
        "    - 결과가 있으면: Answer: ... 형식으로 최종 답변 생성\n",
        "    \"\"\"\n",
        "    message = query_gen_llm.invoke(\n",
        "        query_gen_prompt.format_prompt(messages=state[\"messages\"]).to_messages()\n",
        "    )\n",
        "    return {\"messages\": [message]}\n",
        "\n",
        "workflow.add_node(\"query_gen\", query_gen_node)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8NRIqtN4VBI",
        "outputId": "b27da749-7097-4d49-b835-be029080dc35"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7cd44d9f5c40>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 7) 쿼리 체크 노드 & 실행 노드\n",
        "# =========================================================\n",
        "def model_check_query_node(state: AgentState) -> dict[str, list[AIMessage]]:\n",
        "    # 마지막 메시지를 넣어서 query_check 체인 실행\n",
        "    checked = query_check.invoke({\"messages\": [state[\"messages\"][-1]]})\n",
        "    return {\"messages\": [checked]}\n",
        "\n",
        "workflow.add_node(\"correct_query\", model_check_query_node)\n",
        "workflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGkTvJRV4WI7",
        "outputId": "ca194947-35b3-447e-8dd2-dd04094d8eaf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7cd44d9f5c40>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 8) 조건부 분기 로직\n",
        "# =========================================================\n",
        "def should_continue(state: AgentState) -> Literal[END, \"correct_query\", \"query_gen\"]:\n",
        "    last = state[\"messages\"][-1]\n",
        "    content = getattr(last, \"content\", \"\")\n",
        "\n",
        "    if isinstance(content, str):\n",
        "        if content.startswith(\"Answer:\"):\n",
        "            return END\n",
        "        if content.startswith(\"Error:\"):\n",
        "            # 에러 메시지가 오면 다시 쿼리 생성 시도\n",
        "            return \"query_gen\"\n",
        "        # 그 외는 correct_query로 보냄\n",
        "        return \"correct_query\"\n",
        "    else:\n",
        "        # 리스트/기타 타입이면 일단 correct_query로\n",
        "        return \"correct_query\"\n",
        "\n"
      ],
      "metadata": {
        "id": "nB-4i6Nv4XYZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 9) 엣지 연결 & 그래프 컴파일\n",
        "# =========================================================\n",
        "workflow.add_edge(START, \"first_tool_call\")\n",
        "workflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\n",
        "workflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\n",
        "workflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\n",
        "workflow.add_edge(\"get_schema_tool\", \"query_gen\")\n",
        "\n",
        "workflow.add_conditional_edges(\"query_gen\", should_continue)\n",
        "workflow.add_edge(\"correct_query\", \"execute_query\")\n",
        "workflow.add_edge(\"execute_query\", \"query_gen\")\n",
        "\n",
        "checkpointer = MemorySaver()\n",
        "app = workflow.compile(checkpointer=checkpointer)\n",
        "print(\"LangGraph app compiled.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "des8WpQE4YKr",
        "outputId": "0961317b-b24c-4040-b59f-dc78fdbbf750"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangGraph app compiled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 10) 실행 함수 & 테스트\n",
        "# =========================================================\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "\n",
        "def run_graph(message: str, recursion_limit: int = 30, verbose: bool = True):\n",
        "\n",
        "    config = RunnableConfig(\n",
        "        recursion_limit=recursion_limit,\n",
        "        configurable={\"thread_id\": str(uuid.uuid4())},\n",
        "    )\n",
        "    inputs = {\"messages\": [HumanMessage(content=message)]}\n",
        "    result_state = app.invoke(inputs, config)\n",
        "    msgs = result_state[\"messages\"]\n",
        "    last = msgs[-1]\n",
        "    if verbose:\n",
        "        print(\"---- Last Message ----\")\n",
        "        print(last)\n",
        "        print(\"----------------------\")\n",
        "    return last.content\n",
        "\n",
        "print(\"\\n=== Test 1 ===\")\n",
        "run_graph(\"Andrew Adams 직원의 인적 정보를 모두 조회해줘.\", verbose=True)\n",
        "\n",
        "print(\"\\n=== Test 2 ===\")\n",
        "run_graph(\"2009년에 어느 국가의 고객이 가장 많이 지출했고, 얼마를 지출했는지 알려줘.\", verbose=True)\n"
      ],
      "metadata": {
        "id": "tAX66pkM4N6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 11) LangSmith Evaluator 를 활용한 SQL Agent 평가\n",
        "# =========================================================\n",
        "from langsmith import Client\n",
        "\n",
        "# 클라이언트 초기화\n",
        "client = Client()\n",
        "\n",
        "# 평가용 데이터셋 생성\n",
        "examples = [\n",
        "    (\n",
        "        \"Which country's customers spent the most? And how much did they spend?\",\n",
        "        \"The country whose customers spent the most is the USA, with a total spending of 523.06.\",\n",
        "    ),\n",
        "    (\n",
        "        \"What was the most purchased track of 2013?\",\n",
        "        \"The most purchased track of 2013 was Hot Girl.\",\n",
        "    ),\n",
        "    (\n",
        "        \"How many albums does the artist Led Zeppelin have?\",\n",
        "        \"Led Zeppelin has 14 albums\",\n",
        "    ),\n",
        "    (\n",
        "        \"What is the total price for the album “Big Ones”?\",\n",
        "        \"The total price for the album 'Big Ones' is 14.85\",\n",
        "    ),\n",
        "    (\n",
        "        \"Which sales agent made the most in sales in 2009?\",\n",
        "        \"Steve Johnson made the most sales in 2009\",\n",
        "    ),\n",
        "]\n",
        "\n",
        "dataset_name = \"SQL Agent Response\"\n",
        "\n",
        "if not client.has_dataset(dataset_name=dataset_name):\n",
        "    dataset = client.create_dataset(dataset_name=dataset_name)\n",
        "    inputs, outputs = zip(\n",
        "        *[({\"input\": text}, {\"output\": label}) for text, label in examples]\n",
        "    )\n",
        "    client.create_examples(inputs=inputs, outputs=outputs, dataset_id=dataset.id)\n",
        "    print(\"LangSmith dataset created.\")\n",
        "else:\n",
        "    print(\"LangSmith dataset already exists.\")\n"
      ],
      "metadata": {
        "id": "TMx7oFrpyzq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 12) 에이전트의 SQL 쿼리 응답을 예측하기 위한 함수 정의\n",
        "# =========================================================\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langchain_core.messages import HumanMessage\n",
        "import uuid\n",
        "\n",
        "# 에이전트의 SQL 쿼리 응답을 예측하기 위한 함수 정의\n",
        "def predict_sql_agent_answer(example: dict):\n",
        "    \"\"\"Use this for answer evaluation\"\"\"\n",
        "    config = RunnableConfig(configurable={\"thread_id\": str(uuid.uuid4())})\n",
        "\n",
        "    inputs = {\n",
        "        \"messages\": [HumanMessage(content=example[\"input\"])],\n",
        "    }\n",
        "    # 그래프를 실행하여 메시지 결과 조회\n",
        "    state = app.invoke(inputs, config)\n",
        "    answer = state[\"messages\"][-1].content\n",
        "    # 결과 반환\n",
        "    return {\"response\": answer}\n"
      ],
      "metadata": {
        "id": "5SXBvguzyzs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 13) LLM-as-judge 평가 프롬프트 및 평가자 정의\n",
        "# =========================================================\n",
        "from langchain import hub\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Grade prompt\n",
        "grade_prompt_answer_accuracy = hub.pull(\"langchain-ai/rag-answer-vs-reference\")\n",
        "\n",
        "\n",
        "# 답변 평가자 LLM-as-judge 정의\n",
        "def answer_evaluator(run, example) -> dict:\n",
        "    # input: 질문\n",
        "    input_question = example.inputs[\"input\"]\n",
        "    # output: 참조 답변\n",
        "    reference = example.outputs[\"output\"]\n",
        "    # 예측 답변\n",
        "    prediction = run.outputs[\"response\"]\n",
        "\n",
        "    # LLM 평가자 초기화\n",
        "    llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
        "    answer_grader = grade_prompt_answer_accuracy | llm\n",
        "\n",
        "    # 평가자 실행\n",
        "    score = answer_grader.invoke(\n",
        "        {\n",
        "            \"question\": input_question,\n",
        "            \"correct_answer\": reference,\n",
        "            \"student_answer\": prediction,\n",
        "        }\n",
        "    )\n",
        "    score = score[\"Score\"]\n",
        "\n",
        "    # 점수 반환\n",
        "    return {\"key\": \"answer_v_reference_score\", \"score\": score}\n"
      ],
      "metadata": {
        "id": "_C8asVVpyzvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 14) 평가 실행\n",
        "# =========================================================\n",
        "from langsmith.evaluation import evaluate\n",
        "\n",
        "# 평가용 데이터셋 이름\n",
        "dataset_name = \"SQL Agent Response\"\n",
        "\n",
        "try:\n",
        "    # 평가 진행\n",
        "    experiment_results = evaluate(\n",
        "        predict_sql_agent_answer,  # 평가에 사용할 예측 함수\n",
        "        data=dataset_name,         # 평가용 데이터셋 이름\n",
        "        evaluators=[answer_evaluator],  # 평가자 목록\n",
        "        num_repetitions=3,         # 실험 반복 횟수\n",
        "        experiment_prefix=\"sql-agent-eval\",\n",
        "        metadata={\"version\": \"chinook db, sql-agent-eval: gpt-4o\"},  # 실험 메타데이터\n",
        "    )\n",
        "    print(\"Evaluation finished.\")\n",
        "except Exception as e:\n",
        "    print(\"Evaluation error:\", e)\n"
      ],
      "metadata": {
        "id": "lXQ29P5Fyzw3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}